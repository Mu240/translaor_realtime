<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Real-Time Voice Translator</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    .pulse-ring {
      animation: pulse-ring 1.25s cubic-bezier(0.215, 0.61, 0.355, 1) infinite;
    }
    @keyframes pulse-ring {
      0% { transform: scale(0.33); }
      80%, 100% { opacity: 0; }
    }
    .recording-indicator {
      background: radial-gradient(circle, #ef4444, #dc2626);
      animation: pulse 2s infinite;
    }
    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.7; }
    }
  </style>
</head>
<body class="bg-gradient-to-br from-blue-50 to-indigo-100 min-h-screen flex items-center justify-center p-4">
  <div class="bg-white rounded-2xl shadow-2xl w-full max-w-lg p-8">
    <div class="text-center mb-8">
      <h1 class="text-3xl font-bold text-gray-800 mb-2">Real-Time Translator</h1>
      <p class="text-gray-600">Speak naturally, get instant translations</p>
    </div>

    <!-- Compatibility Warning -->
    <div id="compatibilityWarning" class="bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded-lg mb-4 hidden">
      <strong>Warning:</strong> This app requires HTTPS or localhost to access microphone.
    </div>

    <!-- Device Selection -->
    <div class="space-y-4 mb-6">
      <select id="micSelect" class="w-full p-3 border-2 border-gray-200 rounded-lg focus:border-blue-500 focus:outline-none transition-colors">
        <option value="">Loading microphones...</option>
      </select>
      <select id="targetLang" class="w-full p-3 border-2 border-gray-200 rounded-lg focus:border-blue-500 focus:outline-none transition-colors">
        <option value="French">French</option>
        <option value="Spanish">Spanish</option>
        <option value="German">German</option>
        <option value="Japanese">Japanese</option>
        <option value="Italian">Italian</option>
        <option value="Portuguese">Portuguese</option>
        <option value="Russian">Russian</option>
        <option value="Chinese">Chinese</option>
        <option value="Arabic">Arabic</option>
        <option value="Hindi">Hindi</option>
        <option value="Korean">Korean</option>
        <option value="Dutch">Dutch</option>
        <option value="Swedish">Swedish</option>
        <option value="Norwegian">Norwegian</option>
      </select>
    </div>

    <!-- Recording Controls -->
    <div class="flex justify-center mb-6">
      <div class="relative">
        <button id="startBtn" class="bg-blue-500 hover:bg-blue-600 text-white rounded-full p-6 shadow-lg transition-all duration-200 transform hover:scale-105 disabled:bg-gray-400 disabled:cursor-not-allowed disabled:transform-none">
          <svg class="w-8 h-8" fill="currentColor" viewBox="0 0 20 20">
            <path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clip-rule="evenodd"></path>
          </svg>
        </button>

        <button id="stopBtn" class="recording-indicator text-white rounded-full p-6 shadow-lg hidden">
          <svg class="w-8 h-8" fill="currentColor" viewBox="0 0 20 20">
            <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8 7a1 1 0 00-1 1v4a1 1 0 001 1h4a1 1 0 001-1V8a1 1 0 00-1-1H8z" clip-rule="evenodd"></path>
          </svg>
        </button>

        <!-- Pulse rings for recording indicator -->
        <div id="pulseRings" class="absolute inset-0 hidden">
          <div class="pulse-ring absolute inset-0 border-4 border-red-400 rounded-full"></div>
          <div class="pulse-ring absolute inset-0 border-4 border-red-400 rounded-full animation-delay-75"></div>
        </div>
      </div>
    </div>

    <!-- Status Display -->
    <div class="text-center mb-6">
      <p id="status" class="text-lg font-medium text-gray-700">Checking compatibility...</p>
      <p id="timing" class="text-sm text-gray-500 mt-1"></p>
    </div>

    <!-- Voice Activity Indicator -->
    <div class="flex justify-center mb-6">
      <div class="flex space-x-1">
        <div id="vad1" class="w-2 h-6 bg-gray-300 rounded-full transition-all duration-150"></div>
        <div id="vad2" class="w-2 h-8 bg-gray-300 rounded-full transition-all duration-150"></div>
        <div id="vad3" class="w-2 h-10 bg-gray-300 rounded-full transition-all duration-150"></div>
        <div id="vad4" class="w-2 h-8 bg-gray-300 rounded-full transition-all duration-150"></div>
        <div id="vad5" class="w-2 h-6 bg-gray-300 rounded-full transition-all duration-150"></div>
      </div>
    </div>

    <!-- Results Display -->
    <div id="output" class="space-y-4">
      <div class="bg-blue-50 p-4 rounded-lg">
        <h3 class="font-semibold text-blue-800 mb-2">Original:</h3>
        <p id="transcription" class="text-gray-700 min-h-[2rem]"></p>
      </div>
      <div class="bg-green-50 p-4 rounded-lg">
        <h3 class="font-semibold text-green-800 mb-2">Translation:</h3>
        <p id="translation" class="text-gray-700 font-medium min-h-[2rem]"></p>
      </div>
      <p id="detectedLang" class="text-xs text-gray-500 text-center"></p>
    </div>

    <!-- Audio Playback -->
    <audio id="ttsAudio" class="w-full mt-4 hidden" controls></audio>
  </div>

  <script>
    let stream, audioContext, processor, mediaRecorder;
    let isRecording = false;
    let vadInterval;
    const vadThreshold = 0.005; // Lower threshold for better sensitivity
    const chunkDuration = 1500; // Shorter chunks for faster processing
    let audioQueue = [];
    let isSpeaking = false;
    let isCompatible = false;
    let isProcessing = false;
    let lastProcessTime = 0;
    let silenceStart = 0;
    let silenceDuration = 0;
    const maxSilenceDuration = 800; // Stop recording after 800ms of silence

    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const status = document.getElementById('status');
    const timing = document.getElementById('timing');
    const transcriptionEl = document.getElementById('transcription');
    const translationEl = document.getElementById('translation');
    const detectedLangEl = document.getElementById('detectedLang');
    const micSelect = document.getElementById('micSelect');
    const targetLang = document.getElementById('targetLang');
    const compatibilityWarning = document.getElementById('compatibilityWarning');
    const ttsAudio = document.getElementById('ttsAudio');
    const pulseRings = document.getElementById('pulseRings');

    // VAD indicators
    const vadIndicators = [
      document.getElementById('vad1'),
      document.getElementById('vad2'),
      document.getElementById('vad3'),
      document.getElementById('vad4'),
      document.getElementById('vad5')
    ];

    // Check browser compatibility
    function checkCompatibility() {
      const isSecure = location.protocol === 'https:' || location.hostname === 'localhost' || location.hostname === '127.0.0.1';

      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        compatibilityWarning.classList.remove('hidden');
        status.textContent = 'Browser not supported or insecure context';
        startBtn.disabled = true;
        return false;
      }

      if (!isSecure) {
        compatibilityWarning.classList.remove('hidden');
        status.textContent = 'HTTPS required for microphone access';
        startBtn.disabled = true;
        return false;
      }

      return true;
    }

    // Populate microphone devices
    async function populateMics() {
      try {
        // Request permission first
        await navigator.mediaDevices.getUserMedia({ audio: true });

        const devices = await navigator.mediaDevices.enumerateDevices();
        micSelect.innerHTML = '';

        const audioInputs = devices.filter(device => device.kind === 'audioinput');

        if (audioInputs.length === 0) {
          micSelect.innerHTML = '<option value="">No microphones found</option>';
          return;
        }

        const defaultOption = document.createElement('option');
        defaultOption.value = '';
        defaultOption.text = 'Default Microphone';
        micSelect.appendChild(defaultOption);

        audioInputs.forEach((device, index) => {
          const option = document.createElement('option');
          option.value = device.deviceId;
          option.text = device.label || `Microphone ${index + 1}`;
          micSelect.appendChild(option);
        });

        status.textContent = 'Ready to translate';
      } catch (error) {
        console.error('Error accessing microphones:', error);
        micSelect.innerHTML = '<option value="">Error accessing microphones</option>';
        status.textContent = 'Microphone access denied';
      }
    }

    // Enhanced Voice Activity Detection
    function setupVAD(source) {
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 1024; // Smaller for faster processing
      analyser.smoothingTimeConstant = 0.3;

      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Float32Array(bufferLength);

      source.connect(analyser);

      function updateVAD() {
        if (!isRecording) return;

        analyser.getFloatTimeDomainData(dataArray);

        // Calculate RMS
        let sum = 0;
        for (let i = 0; i < bufferLength; i++) {
          sum += dataArray[i] * dataArray[i];
        }
        const rms = Math.sqrt(sum / bufferLength);

        const currentlySpeaking = rms > vadThreshold;

        // Track silence duration
        if (!currentlySpeaking) {
          if (isSpeaking) {
            silenceStart = Date.now();
          }
          silenceDuration = Date.now() - silenceStart;
        } else {
          silenceDuration = 0;
        }

        isSpeaking = currentlySpeaking;

        // Update visual indicators
        updateVoiceIndicators(rms);

        // Update status
        if (isProcessing) {
          status.textContent = 'Processing...';
        } else if (isSpeaking) {
          status.textContent = 'Listening... (Speaking detected)';
        } else {
          status.textContent = 'Listening... (Waiting for speech)';
        }

        requestAnimationFrame(updateVAD);
      }

      updateVAD();
    }

    // Update voice activity indicators
    function updateVoiceIndicators(level) {
      const normalizedLevel = Math.min(level * 50, 1); // Normalize and amplify

      vadIndicators.forEach((indicator, index) => {
        const threshold = (index + 1) * 0.2;
        if (normalizedLevel > threshold) {
          indicator.style.backgroundColor = isSpeaking ? '#ef4444' : '#3b82f6';
          indicator.style.height = `${1.5 + index * 0.5}rem`;
        } else {
          indicator.style.backgroundColor = '#d1d5db';
          indicator.style.height = `${1 + index * 0.25}rem`;
        }
      });
    }

    // Process audio with optimizations
    async function processAudio(blob) {
      if (isProcessing) return;

      const startTime = Date.now();
      isProcessing = true;
      status.textContent = 'Processing audio...';

      try {
        const reader = new FileReader();
        reader.readAsDataURL(blob);

        reader.onloadend = async () => {
          try {
            const base64Audio = reader.result.split(',')[1];

            const response = await fetch('/transcribe', {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                audio: base64Audio,
                target_language: targetLang.value
              })
            });

            const data = await response.json();

            if (data.error) {
              throw new Error(data.error);
            }

            const processingTime = Date.now() - startTime;
            lastProcessTime = processingTime;

            // Update UI
            transcriptionEl.textContent = data.transcription;
            translationEl.textContent = data.translation;
            detectedLangEl.textContent = `Detected: ${data.detected_language} | Processing: ${processingTime}ms`;
            timing.textContent = `Last processing time: ${processingTime}ms`;

            // Auto-play TTS
            if (data.tts_audio) {
              ttsAudio.src = `data:audio/mp3;base64,${data.tts_audio}`;
              ttsAudio.classList.remove('hidden');

              try {
                await ttsAudio.play();
                status.textContent = 'Playing translation...';
              } catch (playError) {
                console.log('Auto-play prevented');
                status.textContent = 'Translation ready';
              }
            }

          } catch (error) {
            console.error('Processing error:', error);
            status.textContent = `Error: ${error.message}`;
            transcriptionEl.textContent = `Error: ${error.message}`;
          }
        };

      } catch (error) {
        console.error('Error processing audio:', error);
        status.textContent = `Error: ${error.message}`;
      } finally {
        isProcessing = false;
      }
    }

    // Start recording with optimizations
    async function startRecording() {
      if (!isCompatible) {
        alert('Browser not compatible or secure context required');
        return;
      }

      try {
        const constraints = {
          audio: {
            deviceId: micSelect.value ? { exact: micSelect.value } : undefined,
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 16000, // Optimal for Whisper
            channelCount: 1
          }
        };

        stream = await navigator.mediaDevices.getUserMedia(constraints);

        const AudioContextClass = window.AudioContext || window.webkitAudioContext;
        audioContext = new AudioContextClass({ sampleRate: 16000 });

        if (audioContext.state === 'suspended') {
          await audioContext.resume();
        }

        const source = audioContext.createMediaStreamSource(stream);
        setupVAD(source);

        // Setup MediaRecorder with optimized settings
        const options = {
          mimeType: 'audio/webm;codecs=opus',
          audioBitsPerSecond: 16000 // Lower bitrate for speed
        };

        if (!MediaRecorder.isTypeSupported(options.mimeType)) {
          options.mimeType = 'audio/webm';
        }

        mediaRecorder = new MediaRecorder(stream, options);
        let chunks = [];

        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) {
            chunks.push(e.data);
          }
        };

        mediaRecorder.onstop = async () => {
          if (chunks.length > 0) {
            const blob = new Blob(chunks, { type: options.mimeType });
            if (blob.size > 500) { // Minimum size check
              await processAudio(blob);
            }
            chunks = [];
          }
        };

        mediaRecorder.start();

        // Adaptive chunk timing based on speech detection
        vadInterval = setInterval(() => {
          if (isRecording && mediaRecorder && mediaRecorder.state === 'recording') {
            // Process more frequently when speech is detected
            const shouldProcess = isSpeaking || silenceDuration > maxSilenceDuration;

            if (shouldProcess) {
              mediaRecorder.stop();
              setTimeout(() => {
                if (isRecording && !isProcessing) {
                  mediaRecorder.start();
                }
              }, 50); // Shorter delay
            }
          }
        }, chunkDuration);

        // Update UI
        startBtn.classList.add('hidden');
        stopBtn.classList.remove('hidden');
        pulseRings.classList.remove('hidden');
        status.textContent = 'Listening...';
        isRecording = true;

      } catch (error) {
        console.error('Error starting recording:', error);
        handleRecordingError(error);
      }
    }

    // Handle recording errors
    function handleRecordingError(error) {
      status.textContent = `Error: ${error.message}`;

      if (error.name === 'NotAllowedError') {
        alert('Microphone access denied. Please allow microphone access and refresh the page.');
      } else if (error.name === 'NotFoundError') {
        alert('No microphone found. Please connect a microphone and try again.');
      } else if (error.name === 'NotReadableError') {
        alert('Microphone is already in use by another application.');
      }
    }

    // Stop recording
    function stopRecording() {
      isRecording = false;
      isProcessing = false;

      if (vadInterval) {
        clearInterval(vadInterval);
        vadInterval = null;
      }

      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }

      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        stream = null;
      }

      if (audioContext && audioContext.state !== 'closed') {
        audioContext.close();
        audioContext = null;
      }

      // Reset UI
      startBtn.classList.remove('hidden');
      stopBtn.classList.add('hidden');
      pulseRings.classList.add('hidden');
      status.textContent = 'Ready to translate';

      // Reset voice indicators
      vadIndicators.forEach(indicator => {
        indicator.style.backgroundColor = '#d1d5db';
      });
    }

    // Initialize app
    async function initializeApp() {
      isCompatible = checkCompatibility();

      if (isCompatible) {
        await populateMics();
        startBtn.disabled = false;
      }
    }

    // Event listeners
    startBtn.addEventListener('click', startRecording);
    stopBtn.addEventListener('click', stopRecording);

    // Handle page visibility changes
    document.addEventListener('visibilitychange', () => {
      if (document.hidden && isRecording) {
        stopRecording();
      }
    });

    // Handle audio playback events
    ttsAudio.addEventListener('ended', () => {
      if (isRecording) {
        status.textContent = 'Listening...';
      } else {
        status.textContent = 'Ready to translate';
      }
    });

    // Keyboard shortcuts
    document.addEventListener('keydown', (e) => {
      if (e.code === 'Space' && !e.repeat) {
        e.preventDefault();
        if (!isRecording) {
          startRecording();
        }
      }
    });

    document.addEventListener('keyup', (e) => {
      if (e.code === 'Space') {
        e.preventDefault();
        if (isRecording) {
          stopRecording();
        }
      }
    });

    // Initialize when page loads
    window.addEventListener('load', initializeApp);
  </script>
</body>
</html>
